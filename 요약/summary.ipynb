{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM3S5CzB1y+UIYEaEFqWMLm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 학습된 모델 불러오기"],"metadata":{"id":"lKBMV4w0_1Je"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"QlfY4f5S_uev"},"outputs":[],"source":["import pandas as pd\n","import torch\n","from transformers import PreTrainedTokenizerFast\n","from transformers.models.bart import BartForConditionalGeneration\n","import pandas as pd\n","from tqdm import tqdm\n","\n","%cd /content/drive/MyDrive/파일위치/KoBART-summarization\n","model = BartForConditionalGeneration.from_pretrained('./kobart_summary')\n","tokenizer = PreTrainedTokenizerFast.from_pretrained('gogamza/kobart-base-v1')"]},{"cell_type":"markdown","source":["# 판결 요지 정리"],"metadata":{"id":"KGEYx7b0__tm"}},{"cell_type":"code","source":["p = pd.read_pickle((\"/content/drive/MyDrive/파일위치/pan_1_random.pkl\"))\n","panyo_list = list(p['panyo']) #판결요지 리스트\n","avg = 0\n","d = {} #일련번호와 정리된 판결요지를 저장할 딕셔너리\n","#각 문단 별로 저장(각 문단의 평균 길이가 400보다 짧다면 분리하지 않고 저장)\n","for k in range(len(panyo_list)):\n","  pan = panyo_list[k]\n","  if len(pan) < 5:\n","    continue\n","  if len(pan) < 400: #길이가 400보다 짧으면 그대로 저장\n","    d[num_list[k]] = [pan]\n","    continue\n","  # [1] 또는 가. 또는 ① 형태로 번호가 매겨져 있지 않다면 <br/>을 기준으로 나누어 저장\n","  if pan.find('[1]') == -1 and pan.find('가.') == -1 and pan.find('①') == -1:\n","    if len(pan.split('<br/>')) == 1:\n","      continue\n","    s = pan.split('<br/>')\n","    total = 0\n","    for w in s:\n","        total += len(w)\n","    if total/len(s) < 400:\n","          d[num_list[k]] = [pan]\n","    else:\n","          d[num_list[k]] = s\n","  #각 문단이 ① 형태로 매겨져 있을 경우\n","  elif pan.find('①') != -1:\n","    i = 0\n","    s = pan.split('①')\n","    while True:\n","      try:\n","        s[i+1].index(chr(ord('①')+i+1)) #숫자를 하나씩 늘려가며 인덱스를 찾음\n","        s= [s[i]] + pan.split(chr(ord('①')+i+1)) #오류가 나지 않는다면 존재한다는 의미이므로 해당 기호로 분리\n","        i += 1\n","      except: #\n","        total = 0\n","        for w in s:\n","          total += len(w)\n","        if total/len(s) < 400:\n","          d[num_list[k]] = [pan]\n","        else:\n","          print(k)\n","          d[num_list[k]] = s\n","        break\n","  #각 문단이 가. 형태로 매겨져 있을 경우\n","  elif pan.find('가.') != -1:\n","    han_list=['가.', '나.', '다.', '라.', '마.', '바.', '사.'] #확인 결과 사. 이상인 것은 없었음\n","    s_list = pan.split('<br/>') #일차적으로 <br/>을 기준으로 나누기\n","    i = 0\n","    for _ in range(len(s_list)):\n","      s = s_list[i]\n","      if len(s) < 15:\n","        s_list.remove(s)\n","      else:\n","        s_list[i] = s.strip()\n","        i += 1\n","    for s in s_list:\n","      if len(s) < 15:\n","        continue\n","      c = 0\n","       #han_list 중 하나로 시작하는지 확인\n","      for h in han_list:\n","        if s.find(h) == 0:\n","          c = 1\n","          break\n","      if c == 0: #han_list의 요소로 시작하지 않을 경우\n","         #마지막 문단이면 위 문단과 합치고 아니라면 s_list를 비운다(예외 상황이 너무 많아서 그냥 없앰)\n","        if s_list.index(s) == len(s_list) -1:\n","          s_list.remove(s)\n","          s_list[len(s_list) -1] += s\n","        else:\n","          s_list = []\n","          break\n","    #S_list가 빈 리스트가 아니라면 d(전체 딕셔너리)에 추가\n","    if len(s_list) > 0:\n","      total = 0\n","      for w in s_list:\n","          total += len(w)\n","      if total/len(s_list) < 400:\n","          d[num_list[k]] = [pan]\n","      else:\n","          print(k)\n","          d[num_list[k]] = s_list\n","  #각 문단이 [1] 형태로 매겨져 있을 경우\n","  elif pan.find('[1]') != -1:\n","    i = 0\n","    s = pan.split('[1]')\n","    #하나씩 숫자를 높여가며 찾다가 없으면(오류가 나면) 저장 후 반복문 종료\n","    while True:\n","      try:\n","        s[i+1].index('[' + str(i) +']')\n","        s= [s[i]] + pan.split('[' + str(i) +']')\n","        i += 1\n","      except:\n","        total = 0\n","        for w in s:\n","          total += len(w)\n","        if total/len(s) < 400:\n","          d[num_list[k]] = [pan]\n","        else:\n","          d[num_list[k]] = s\n","        break\n","precedentDic = {}\n","precedentDic['number'] = list(d.keys())\n","precedentDic['contents'] = list(d.values())\n","p_obj = pd.DataFrame(precedentDic, columns = ['number', 'contents'])\n","p_obj.to_pickle(\"/content/drive/MyDrive/파일위치/panyo_1_random_8000_split.pkl\")\n"],"metadata":{"id":"7Rn4AmW2_7F5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 요약"],"metadata":{"id":"hwqJYZVuAOEf"}},{"cell_type":"markdown","source":["## 요약_ 조금씩 나눠서 진행"],"metadata":{"id":"l8ukgp7PAYXI"}},{"cell_type":"code","source":["from tqdm import tqdm\n","panD = {}\n","p_obj = pd.read_pickle('/content/drive/MyDrive/파일위치/panyo_1_random_8000_split.pkl' )\n","for d in tqdm(range(3000, len(p_obj))):\n","    output = ''\n","    for s in [p_obj['contents'][d]]: #각 문단 별로\n","      if len(s) < 5:\n","        continue\n","      elif len(s) < 50: #길이가 50보다 작으면 요약하지 않고 원문 저장\n","        panD[p_obj['number'][d]] = p_obj['contents'][d]\n","        continue\n","      input_ids = tokenizer.encode(s)\n","      if len(input_ids) > 1026: #이 경우 오랫동안 실행되다가 오류가 나서 바로 중단하도록 함\n","        break\n","      input_ids = torch.tensor(input_ids)\n","      input_ids = input_ids.unsqueeze(0)\n","      out = model.generate(input_ids, eos_token_id=1, max_length=1024, num_beams=5)\n","      out = tokenizer.decode(out[0], skip_special_tokens=True)\n","      output += out + '\\n'\n","    panD[p_obj['number'][d]] = output\n","    if len(panD) != 0 and len(panD) % 100 == 0:\n","      precedentDic = {}\n","      precedentDic['number'] = list(panD.keys())\n","      precedentDic['contents'] = list(panD.values())\n","      p = pd.DataFrame(precedentDic, columns = ['number', 'contents'])\n","      p.to_pickle(\"/content/drive/MyDrive/파일위치/panyo_summary_1_random_8000_split(3).pkl\")\n"],"metadata":{"id":"_nGgtMPwAJP8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 데이터 프레임 합치기"],"metadata":{"id":"I-Ehq0aLASQo"}},{"cell_type":"code","source":["import pandas as pd\n","dList = []\n","df = []\n","dList.append(pd.read_pickle(\"/content/drive/MyDrive/파일위치/panyo_summary_1_random_8000_split.pkl\"))\n","dList.append(pd.read_pickle(\"/content/drive/MyDrive/파일위치/panyo_summary_1_random_8000_split(2).pkl\"))\n","dList.append(pd.read_pickle(\"/content/drive/MyDrive/파일위치/panyo_summary_1_random_8000_split(3).pkl\"))\n","df = pd.concat(dList, sort=False)\n","df.index = range(len(df))\n","df.to_pickle(\"/content/drive/MyDrive/파일위치/panyo_summary_1_random_8000.pkl\")\n"],"metadata":{"id":"1ZiHGtxiAtRt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","dList = []\n","df = []\n","dList.append(pd.read_pickle(\"/content/drive/MyDrive/파일위치/panyo_summary_1_random_8000.pkl\"))\n","dList.append(pd.read_pickle(\"/content/drive/MyDrive/파일위치/panyo_summary_2_random_8000.pkl\"))\n","dList.append(pd.read_pickle(\"/content/drive/MyDrive/파일위치/panyo_summary_3_random_8000.pkl\"))\n","dList.append(pd.read_pickle(\"/content/drive/MyDrive/파일위치/panyo_summary_4_random_8000.pkl\"))\n","dList.append(pd.read_pickle(\"/content/drive/MyDrive/파일위치/panyo_summary_5_random_8000.pkl\"))\n","dList.append(pd.read_pickle(\"/content/drive/MyDrive/파일위치/panyo_summary_6_random_8000.pkl\"))\n","dList.append(pd.read_pickle(\"/content/drive/MyDrive/파일위치/panyo_summary_7_random_8000.pkl\"))\n","df = pd.concat(dList, sort=False)\n","df.index = range(len(df))\n","df.to_pickle(\"/content/drive/MyDrive/파일위치/panyo_summary_total_random_8000.pkl\")\n"],"metadata":{"id":"X84uO5CZAci_"},"execution_count":null,"outputs":[]}]}